---
title: Highway Assignment
echo: false
warning: false
message: false
---

```{python}
#libraries
import os
import pandas as pd
import geopandas as gpd
import numpy as np
import matplotlib.pyplot as plt
import contextily as ctx
import _validation_scripts as vs
import openmatrix as omx
import geopandas as gpd
from shapely.geometry import Point
import math
import glob

# inputs
df_obs_path = r"data/5-assignhwy/observed-volumes.csv"
df_mod_path = r"data/5-assignhwy/WFv910_BY_2019_Summary_SEGID.csv"
omx_path = r"../../../_large_files/v910/5_FinalNetSkims/"
geojson_file = r'data/5-assignhwy/tazNew.geojson'

# read segment shapefile into spatial enabled dataframe
dirSegShp = r'data/5-assignhwy/seg_shp/WFv910_Segments.shp'
segShp = gpd.read_file(dirSegShp)
segShp.head()
segShp = segShp[['SEGID','geometry']]
```

## Volumes

Model volumes and vehicle-miles travel (VMT) were validated against observed data. The observed data for 2019 volumes is taken from the Utah Department of Transportation (UDOT) [Average Annual Daily Traffic (AADT) History](https://drive.google.com/file/d/1rDXm0ObugGR1zXgWUuVbzWHNt-Xs1xru/view) and associated with their respective model segments. Observed VMT was calculated by multiplying the observed volume by the model segment distances.

@fig-assign-validation shows model and observed values for the region at the all vehicle, medium truck, and heavy truck levels. The comparisons are shown in four different types of charts and tables:

 - *Average Daily Volume by Roadway Class (2a)*: The daily volume is averaged across all segments within their respective geography and vehicle type.
 - *Total VMT by Roadway Class (2b)*: For each segment, the daily volume is multiplied by segment distance and then summed across all segments within their respective geography and vehicle type.
 - *Model vs Count Segment Volume (2c)*: This is a scatter plot of segment daily volume with the x-axis as the observed volume and the y-axis as the model volume. The gray line shows the location of where model and observed volumes are equal. The dashed blue line shows a least-squares linear regression. The further the blue line moved away from the gray line, the further the model is from observed.
 - *Segment Percent Error (2d)*: This is a scatter plot showing the amount of error (percent difference) between the observed volume and the model volume. The observed volume is the x-axis and the percent error is the y-axis. The gray lines are a bounding box that shows the control target. As volume increases, it is expected that the percent error should decrease.


```{ojs}
import {GroupedBarChart} from "@d3/grouped-bar-chart"
import {Legend, Swatches} from "@d3/color-legend"
import {howto, altplot} from "@d3/example-components"
```

```{python}
#read in model/observed data
df_obs = pd.read_csv(df_obs_path)
df_mod = pd.read_csv(df_mod_path)
df_ft = df_mod[['SEGID','FTCLASS']]
df_fc = df_obs[['SEGID','Valid_FC']]

# prep comparison dfs for ojs volume summary comparisons
df_mod1 = df_mod.copy()
df_mod1['Mod_Car'] = df_mod1['DY_Vol_PC'] + df_mod1['DY_Vol_LT']
df_mod1 = df_mod1.rename(columns={'DY_Vol':'Mod_AWDT','DY_Vol_MD':'Mod_MD','DY_Vol_HV':'Mod_HV'})
df_mod1 = df_mod1[['SEGID','CO_FIPS','DISTANCE','Mod_AWDT','Mod_Car','Mod_MD','Mod_HV']]

df_obs1 = df_obs[['SEGID', 'Obs_AWDT', 'Obs_Car', 'Obs_MD', 'Obs_HV']]
allveh = pd.merge(df_mod1,df_obs1,on='SEGID',how='left')
allveh = pd.merge(allveh,df_fc, on='SEGID', how='left')
```

```{python}
# prep map comparison of volumes
df_obs[['data']] = 'Observed'
df_mod[['data']] = 'Modeled'

# observed
df_obs = df_obs[['SEGID','data','Obs_AWDT','Obs_Car','Obs_MD','Obs_HV']].rename(columns={'Obs_AWDT':'Total','Obs_Car':'Car','Obs_MD':'MD','Obs_HV':'HV'})

#modeled
df_mod['Car'] = df_mod['DY_Vol_PC'] + df_mod['DY_Vol_LT']
df_mod = df_mod.rename(columns={'DY_Vol':'Total','DY_Vol_MD':'MD','DY_Vol_HV':'HV'})
df_mod = df_mod[['SEGID','data','Total', 'Car','MD', 'HV']]
```

```{python}
# create one large dataframe before creating maps
dfSegSum = pd.concat([df_mod,df_obs],ignore_index=True)
dfSegSum = pd.merge(dfSegSum,df_ft,on='SEGID',how='left')
```

```{python}
# create volume comparison maps
vs.plot_volume_diff(dfSegSum,'Total', segShp)
vs.plot_volume_diff(dfSegSum,'Total', segShp) # not sure why i need to run this twice...
#vs.plot_volume_diff(dfSegSum,'Car', segShp)
vs.plot_volume_diff(dfSegSum,'MD', segShp)
vs.plot_volume_diff(dfSegSum,'HV', segShp)
```

```{python}
# prep data for volume summary comparison plots
columns_to_convert = [
    'Mod_AWDT', 'Obs_AWDT',
    'Mod_Car', 'Obs_Car',
    'Mod_MD', 'Obs_MD',
    'Mod_HV', 'Obs_HV'
]

# Convert specified columns to numeric, coercing errors to NaN
allveh[columns_to_convert] = allveh[columns_to_convert].apply(pd.to_numeric, errors='coerce')

# Verify conversion

allveh.rename(columns={'Valid_FC':'funcClass'}, inplace=True)

# create a copy for 'All Roadways' category
_allfc = allveh.copy()
_allfc['funcClass'] = 'All Roadways'

allveh = pd.concat([allveh,_allfc])

# manually 'melt' veh type
_dfPC = allveh[['SEGID', 'DISTANCE', 'CO_FIPS', 'funcClass', 'Mod_Car' ,'Obs_Car' ]].rename(columns={'Mod_Car' :'volMod', 'Obs_Car' :'volObs', 'CO_FIPS':'coFips'})
_dfMD = allveh[['SEGID', 'DISTANCE', 'CO_FIPS', 'funcClass', 'Mod_MD'  ,'Obs_MD'  ]].rename(columns={'Mod_MD'  :'volMod', 'Obs_MD'  :'volObs', 'CO_FIPS':'coFips'})
_dfHV = allveh[['SEGID', 'DISTANCE', 'CO_FIPS', 'funcClass', 'Mod_HV'  ,'Obs_HV'  ]].rename(columns={'Mod_HV'  :'volMod', 'Obs_HV'  :'volObs', 'CO_FIPS':'coFips'})
_dfAl = allveh[['SEGID', 'DISTANCE', 'CO_FIPS', 'funcClass', 'Mod_AWDT','Obs_AWDT']].rename(columns={'Mod_AWDT':'volMod', 'Obs_AWDT':'volObs', 'CO_FIPS':'coFips'})

# add vehicle types
_dfPC['vehType'] = 'Passenger Cars'
_dfMD['vehType'] = 'Medium Trucks'
_dfHV['vehType'] = 'Heavy Trucks'
_dfAl['vehType'] = 'All Vehicles'

# combine
allveh = pd.concat([_dfPC, _dfMD, _dfHV, _dfAl])

# calc diffSquare
allveh['volDiffSq'  ] = (allveh['volMod'] - allveh['volObs']) ** 2 #squared
allveh['volErrorPct'] = (allveh['volMod'] - allveh['volObs']) / allveh['volObs']

# recalc VMT
allveh['vmtMod'] = allveh['volMod'] * allveh['DISTANCE']
allveh['vmtObs'] = allveh['volObs'] * allveh['DISTANCE']

# remove nulls
allveh.dropna(inplace=True)
#allvehfc

allveh2 = allveh.copy()
allveh2['coFips'] = 'Region'
allveh = pd.concat([allveh, allveh2])
#allveh
```

```{python}
agg_functions = {'SEGID'     : 'count',
                 'volMod'    : 'mean',
                 'volObs'    : 'mean',
                 'volDiffSq' : lambda x: np.sqrt(np.sum(x) / (x.nunique() - 1)),# this is right, excel is wrong (excel is only using sum at county level)
                 'vmtMod'    : 'sum',
                 'vmtObs'    : 'sum'} 

#summarize allveh to create daily comparison by coFips, funcClass, vehType tables
allveh_sum = allveh.groupby(['coFips','funcClass','vehType']).agg(agg_functions).reset_index()
allveh_sum = allveh_sum.rename(columns={'SEGID':'numSegs','volDiffSq':'volRmse'})

allveh_sum['volDiff'   ] = allveh_sum['volMod'] - allveh_sum['volObs']
allveh_sum['vmtDiff'   ] = allveh_sum['vmtMod'] - allveh_sum['vmtObs']

allveh_sum['volDiffPct'] = allveh_sum['volDiff'] / allveh_sum['volObs']
allveh_sum['vmtDiffPct'] = allveh_sum['vmtDiff'] / allveh_sum['vmtObs']

allveh_sum['volRmsePct'   ] = (allveh_sum['volRmse'] / allveh_sum['volObs'])

allveh_sum_copy = allveh_sum.copy()
```

```{python}
allveh_vol = allveh_sum[['coFips','funcClass','vehType','numSegs','volMod','volObs','volDiff','volDiffPct','volRmse','volRmsePct']]
allveh_vmt = allveh_sum[['coFips','funcClass','vehType','numSegs','vmtMod','vmtObs','vmtDiff','vmtDiffPct']]
```

```{python}
allveh_pct = allveh_sum[['coFips','funcClass','vehType','volDiffPct','vmtDiffPct']]
allveh_pct = allveh_pct.melt(id_vars=['coFips','funcClass','vehType'], value_vars=['volDiffPct','vmtDiffPct'], var_name='Variable', value_name='Value')
allveh_pct = allveh_pct.pivot(index=['funcClass','vehType','Variable'], columns='coFips', values='Value').reset_index()
allveh_pct = allveh_pct[['Variable', 'funcClass','vehType', 'Region', 3, 57, 11, 35, 49]]
```

```{python}
allveh_pct_exact = allveh_sum_copy[['coFips','funcClass','vehType','volDiffPct','vmtDiffPct']]
allveh_pct_exact = allveh_pct_exact.melt(id_vars=['coFips','funcClass','vehType'], value_vars=['volDiffPct','vmtDiffPct'], var_name='Variable', value_name='Value')
allveh_pct_exact = allveh_pct_exact.pivot(index=['funcClass','vehType','Variable'], columns='coFips', values='Value').reset_index()
allveh_pct_exact = allveh_pct_exact[['Variable','funcClass','vehType','Region',3,57,11,35,49]]
allveh_pct_exact = allveh_pct_exact.melt(id_vars = ['funcClass','vehType', 'Variable'], value_vars = ['Region',3,57,11,35,49], value_name='Value', var_name='Region')
```

```{python}
allveh_abs_exact = allveh_sum_copy[['coFips', 'funcClass', 'volMod', 'volObs', 'vmtMod', 'vmtObs']]
allveh_abs_exact = allveh_abs_exact.melt(id_vars = ['coFips','funcClass'], value_vars = ['volMod', 'volObs', 'vmtMod', 'vmtObs'], var_name = 'DataSource',value_name = 'Value')
allveh_abs_exact['Variable'] = allveh_abs_exact['DataSource'].apply(lambda x: 'Volume' if 'Volume' in x else 'VMT')
allveh_abs_exact['DataSource'] = allveh_abs_exact['DataSource'].apply(lambda x: 'Model' if 'Model' in x else 'Observed')
allveh_abs_region = allveh_abs_exact[allveh_abs_exact['coFips'] == 'Region']
```

```{python}
allveh_vol_long = allveh_vol.rename(columns={'volMod':'Model','volObs':'Observed'})
allveh_vol_long = pd.melt(allveh_vol_long,
                          id_vars =['coFips','funcClass','vehType'],
                          value_vars = ['Model', 'Observed'],
                          var_name = 'DataSource',
                          value_name = 'ViewValue')
allveh_vol_long['ViewValue'] = allveh_vol_long['ViewValue'] / 1000
allveh_vmt_long = allveh_vmt.rename(columns={'vmtMod':'Model','vmtObs':'Observed'})
allveh_vmt_long = pd.melt(allveh_vmt_long,
                          id_vars =['coFips','funcClass','vehType'],
                          value_vars = ['Model', 'Observed'],
                          var_name = 'DataSource',
                          value_name = 'ViewValue')     
allveh_vmt_long['ViewValue'] = allveh_vmt_long['ViewValue'] / 1000000


# summary chart

allveh_vol_diff_long = pd.melt(allveh_vol,
                               id_vars =['coFips','funcClass','vehType'],
                               value_vars = ['volDiff', 'volDiffPct'],
                               var_name = 'View',
                               value_name = 'ViewValue')


allveh_vmt_diff_long = pd.melt(allveh_vmt,
                               id_vars =['coFips','funcClass','vehType'],
                               value_vars = ['vmtDiff', 'vmtDiffPct'],
                               var_name = 'View',
                               value_name = 'ViewValue')

# Create a mapping dictionary for the coFips values
fips_mapping = {
    3: 'Box Elder County - WFRC',
    11: 'Davis County',
    35: 'Salt Lake County',
    49: 'Utah County',
    57: 'Weber County - WFRC'
}
# Use the `replace` method on the 'coFips' column
allveh_vol_diff_long['coFips'] = allveh_vol_diff_long['coFips'].replace(fips_mapping)
allveh_vmt_diff_long['coFips'] = allveh_vmt_diff_long['coFips'].replace(fips_mapping)

def round_up_to_next_significant(value):
    if value == 0 or np.isinf(value) or np.isnan(value):
        return 0
    magnitude = 10 ** math.floor(math.log10(value))
    return math.ceil(value / magnitude) * magnitude

max_abs_value_volDiff    = round_up_to_next_significant(allveh_vol_diff_long.query("View == 'volDiff'"   )['ViewValue'].abs().max())
max_abs_value_vmtDiff    = round_up_to_next_significant(allveh_vmt_diff_long.query("View == 'vmtDiff'"   )['ViewValue'].abs().max())
max_abs_value_volDiffPct = round_up_to_next_significant(allveh_vol_diff_long.query("View == 'volDiffPct'")['ViewValue'].abs().max())
max_abs_value_vmtDiffPct = round_up_to_next_significant(allveh_vmt_diff_long.query("View == 'vmtDiffPct'")['ViewValue'].abs().max())

# scatter plot dataframe
allvehplot = allveh[['SEGID','coFips','funcClass','vehType','volMod','volObs','volErrorPct']].copy()
allvehplot['volMod'] = allvehplot['volMod'] / 1000 # reduce so axis labels are shorter
allvehplot['volObs'] = allvehplot['volObs'] / 1000 # reduce so axis labels are shorter
```

```{python}
#display(allveh_vol)
#filtered_df = allveh_vol[(allveh_vol['funcClass'] == 'Freeway') & (allveh_vol['vehType'] == 'Passenger Cars') & (allveh_vol['coFips'] == 'Region')]
#volMod_sum = filtered_df['volMod'].sum()

#display(volMod_sum)
```

```{python}
# save as ojs objects

# for summary comparison
ojs_define(volDiffLong = allveh_vol_diff_long) 
ojs_define(vmtDiffLong = allveh_vmt_diff_long)

# for detailed comparison
ojs_define(vol = allveh_vol) 
ojs_define(vmt = allveh_vmt)
ojs_define(volLong = allveh_vol_long)
ojs_define(vmtLong = allveh_vmt_long)
ojs_define(allvehplot = allvehplot) # for scatter plot

# use?
ojs_define(vvpct = allveh_pct)
ojs_define(vvpctLong = allveh_pct_exact)
ojs_define(vvabsLong = allveh_abs_exact)
ojs_define(vvabsLongR = allveh_abs_region)

ojs_define(max_abs_value_volDiff    = max_abs_value_volDiff   )
ojs_define(max_abs_value_vmtDiff    = max_abs_value_vmtDiff   )
ojs_define(max_abs_value_volDiffPct = max_abs_value_volDiffPct)
ojs_define(max_abs_value_vmtDiffPct = max_abs_value_vmtDiffPct)


```


```{ojs}
html`<br/>`
viewof bCountySelect = Inputs.select(new Map([['Region', 'Region']]), {value: 'All', label: "Geography:"})
//viewof bCountySelect = Inputs.select(new Map([['Region', 'Region'], ['Box Elder County - WFRC',3], ['Weber County - WFRC',57], ['Davis County',11], ['Salt Lake County',35], ['Utah County',49]]), {value: 'All', label: "Geography:"})
viewof bVehType = Inputs.select(new Map([['All Vehicles','All Vehicles'], ['Medium Trucks','Medium Trucks'], ['Heavy Trucks','Heavy Trucks']]), {value: 'All Vehicles', label: "Vehicle Type:"})
//viewof bVehType = Inputs.select(new Map([['All Vehicles','All Vehicles'], ['Passenger Cars', 'Passenger Cars'], ['Medium Trucks','Medium Trucks'], ['Heavy Trucks','Heavy Trucks']]), {value: 'All Vehicles', label: "Vehicle Type:"})

sortOrder = ['Freeway', 'Principal', 'Minor', 'Collector', 'All Roadways'];

volT = transpose(vol)
vmtT = transpose(vmt)
filtered_volData = volT.filter(function(dataL) {
    return bCountySelect == dataL.coFips &&
           bVehType == dataL.vehType;
}).sort((a, b) => sortOrder.indexOf(a.funcClass) - sortOrder.indexOf(b.funcClass));
filtered_vmtData = vmtT.filter(function(dataL){
    return bCountySelect == dataL.coFips &&
           bVehType == dataL.vehType;
}).sort((a, b) => sortOrder.indexOf(a.funcClass) - sortOrder.indexOf(b.funcClass));

volTL = transpose(volLong)
vmtTL = transpose(vmtLong)
filtered_volDataL = volTL.filter(function(dataL) {
    return bCountySelect == dataL.coFips &&
           bVehType == dataL.vehType;
}).sort((a, b) => sortOrder.indexOf(a.funcClass) - sortOrder.indexOf(b.funcClass));
filtered_vmtDataL = vmtTL.filter(function(dataL){
    return bCountySelect == dataL.coFips &&
           bVehType == dataL.vehType;
}).sort((a, b) => sortOrder.indexOf(a.funcClass) - sortOrder.indexOf(b.funcClass));


allvehplotT = transpose(allvehplot)
filtered_allvehplotData = allvehplotT.filter(function(dataL) {
    return bCountySelect == dataL.coFips &&
           bVehType == dataL.vehType;
});

```


:::: {.columns}
::: {.column width="65%"}

```{ojs}
//| echo: false
function formatNumber(value, isPercentage=false) {
    if (typeof value === 'undefined') {
        return '';  // or return a default value or message
    }
    
    if (isPercentage) {
        return (Number(value) * 100).toFixed(1) + '%';
    }
    return Number(value.toFixed(0)).toLocaleString();
}

widthsVol = ['100px', '52px', '70px', '70px', '73px', '73px', '63px', '63px']; // Define the widths
widthsVmt = ['100px', '88px', '88px', '88px', '88px']; // Define the widths
```

```{ojs}
//| echo: false
html`
<h4>2a. Average Daily Volume by Roadway Class</h4>
<table>
    <thead>
    <tr>
        ${["Roadway Class", "# Segs", "Volume", "Observed", "Difference", "Percent Difference", "RMSE", "Percent RMSE"].map((d, i) => {
            return html`<th style='text-align: ${i === 0 ? "left" : "right"}; padding: 5px; width: ${widthsVol[i]};'>${d}</th>`;
        })}
    </tr>
    </thead>
    <tbody>
        ${filtered_volData.map(row => {
            const isBold = row['funcClass'] === 'All Roadways';
            return html`<tr style='border-bottom: 1px solid lightgrey;'>
                ${["funcClass", "numSegs", "volMod", "volObs", "volDiff", "volDiffPct", "volRmse", "volRmsePct"].map((d, i) => {
                    // Check if the current cell is one of the numeric columns that need formatting
                    let formattedValue;
                    if (i === 5 || i === 7) {
                        formattedValue = formatNumber(row[d], true);  // True for percentage formatting
                    } else if ((i >= 1 && i <= 4) || i==6) {
                        formattedValue = formatNumber(row[d]);
                    } else {
                        formattedValue = row[d];
                    }
                    return html`<td style='text-align: ${i === 0 ? "left" : "right"}; padding: 5px; font-weight: ${isBold ? 'bold' : 'normal'};'>${formattedValue}</td>`;
                })}
            </tr>`;
        })}
    </tbody>
</table>`
```

:::
::: {.column width="35%"}

```{ojs}
html`<h4>&nbsp;</h4>`
keyVol = Legend(bChartVol.scales.color, {title: "Data Source"})

bChartVol = GroupedBarChart(filtered_volDataL, {
    x: d => d.funcClass,
    y: d => d.ViewValue,
    z: d => d.DataSource,
    xDomain: ['Freeway','Principal','Minor','Collector','All Roadways'],
    yLabel: "Average Volume (thousands)",
    zDomain: ['Model','Observed'],
    width: 320,
    height: 175,
    colors: ["#376092", "#77933c"]
})
```

:::
::::

:::: {.columns}
::: {.column width="65%"}

```{ojs}
html`
<h4>2b. Total Daily VMT by Roadway Class</h4>
<table>
    <thead>
    <tr>
        ${["Roadway Class", "Model", "Observed", "Difference", "Percent Difference"].map((d, i) => {
            return html`<th style='text-align: ${i === 0 ? "left" : "right"}; padding: 5px; width: ${widthsVmt[i]};'>${d}</th>`;
        })}
    </tr>
    </thead>
    <tbody>
        ${filtered_vmtData.map(row => {
            const isBold = row['funcClass'] === 'All Roadways';
            return html`<tr style='border-bottom: 1px solid lightgrey;'>
                ${["funcClass", "vmtMod", "vmtObs", "vmtDiff", "vmtDiffPct"].map((d, i) => {
                    // Check if the current cell is one of the numeric columns that need formatting
                    let formattedValue;
                    if (i === 4 || i === 6) {
                        formattedValue = formatNumber(row[d], true);  // True for percentage formatting
                    } else if ((i >= 1 && i <= 3) || i==5) {
                        formattedValue = formatNumber(row[d]);
                    } else {
                        formattedValue = row[d];
                    }
                    return html`<td style='text-align: ${i === 0 ? "left" : "right"}; padding: 5px; font-weight: ${isBold ? 'bold' : 'normal'};'>${formattedValue}</td>`;
                })}
            </tr>`;
        })}
    </tbody>
</table>`
```

:::
::: {.column width="35%"}

```{ojs}
html`<h4>&nbsp;</h4>`
keyVmt = Legend(bChartVmt.scales.color, {title: "Data Source"})

bChartVmt = GroupedBarChart(filtered_vmtDataL, {
    x: d => d.funcClass,
    y: d => d.ViewValue,
    z: d => d.DataSource,
    xDomain: ['Freeway','Principal','Minor','Collector','All Roadways'],
    yLabel: "Total VMT (millions)",
    zDomain: ['Model','Observed'],
    width: 320,
    height: 175,
    colors: ["#376092", "#77933c"]
})
```

:::
::::

:::: {.columns}
::: {.column width="50%"}

```{ojs}
import {max} from 'd3-array';
```

```{ojs}

maxVal = {
  return Math.max(
    d3.max(filtered_allvehplotData, d => d.volObs),
    d3.max(filtered_allvehplotData, d => d.volMod)
  );
}

```

```{ojs}
html`<h4>2c. Model vs Observed Volumes</h4>`
Plot.plot({
  grid: true,
  width: 460,
  height: 300,
  marginRight: 40,
  x: {
    label: "Observed Volume (thousands)",
    domain: [0, maxVal]
  },
  y: {
    label: "Model Volume (thousands)",
    domain: [0, maxVal]
  },
  marks: [
    Plot.dot(filtered_allvehplotData, {
      x: "volObs",
      y: "volMod",
      r: 1,
      fill: "rgb(80, 116, 230)",
      fillOpacity: 0.5,
      stroke: "none"
    }),
    Plot.link([0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4], {
      x1: 0,
      y1: 0,
      x2: maxVal,
      y2: (k) => maxVal * k,
      strokeOpacity: (k) => k === 1 ? 1 : 0.2,
      stroke: "gray",
      strokeWidth: (k) => k === 1 ? 2 : 1.5
    }),
    Plot.text([0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3, 1.4], {
      x: maxVal,
      y: (k) => maxVal * k,
      text: ((f) => (k) => k === 1 ? "Equal" : f(k - 1))(d3.format("+.0%")),
      textAnchor: "start",
      dx: 6
    }),
    // New top-aligned labels
    Plot.text([1.4, 1.3, 1.2, 1.1, 1, 0.1, 0.2, 0.3, 0.4], {
      x: (k2) => maxVal * 0.8 * (1-k2),
      y: maxVal,
      text: ((f) => (k2) => k2 === 1 ? "" : f(1-k2))(d3.format("+.0%")), //(k2) => d3.format("+.0%")(1-k2),
      textAnchor: "middle",
      dy: -10, // Adjusts position slightly above the top of the plot
      dx: 392
    }),
    Plot.linearRegressionY(filtered_allvehplotData, {
        x: "volObs",
        y: "volMod",
        stroke: "rgb(80, 116, 230)",
        strokeDasharray: "4 4",  // This creates a dashed line pattern,
        strokeWidth: 2 
    })
  ]
})
```
:::
::: {.column width="50%"}

```{ojs}
html`<h4>2d. Model vs Observed Percent Error</h4>`
// volErrorPct
Plot.plot({
  grid: true,
  width: 460,
  height: 300,
  marginRight: 40,
  x: {
    label: "Observed Volume (thousands)",
    domain: [0, maxVal]
  },
  y: {
    label: "Percent Error",
    domain: [-2, 2],
    tickFormat: d3.format(".0%")
  },
  marks: [
    Plot.dot(filtered_allvehplotData, {
      x: "volObs",
      y: "volErrorPct",
      r: 1,
      fill: "rgb(80, 116, 230)",
      fillOpacity: 0.5,
      stroke: "none"
    }),
    Plot.ruleY([2], {
      x1: 0,
      x2: 1,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([1], {
      y1: 1,
      y2: 2,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([1], {
      x1: 1,
      x2: 2.5,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([2.5], {
      y1: 0.5,
      y2: 1.0,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([0.5], {
      x1: 2.5,
      x2: 5,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([5], {
      y1: 0.25,
      y2: 0.50,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([0.25], {
      x1: 5,
      x2: 10,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([10], {
      y1: 0.20,
      y2: 0.25,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([0.20], {
      x1: 10,
      x2: 25,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([25], {
      y1: 0.15,
      y2: 0.20,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([0.15], {
      x1: 25,
      x2: 50,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([50], {
      y1: 0.10,
      y2: 0.15,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([0.10], {
      x1: 50,
      x2: 300,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-2], {
      x1: 0,
      x2: 1,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([1], {
      y1: -1,
      y2: -2,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-1], {
      x1: 1,
      x2: 2.5,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([2.5], {
      y1: -0.5,
      y2: -1.0,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-0.5], {
      x1: 2.5,
      x2: 5,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([5], {
      y1: -0.25,
      y2: -0.50,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-0.25], {
      x1: 5,
      x2: 10,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([10], {
      y1: -0.20,
      y2: -0.25,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-0.20], {
      x1: 10,
      x2: 25,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([25], {
      y1: -0.15,
      y2: -0.20,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-0.15], {
      x1: 25,
      x2: 50,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleX([50], {
      y1: -0.10,
      y2: -0.15,
      stroke: "gray",
      strokeWidth: 2
    }),
    Plot.ruleY([-0.10], {
      x1: 50,
      x2: 300,
      stroke: "gray",
      strokeWidth: 2
    })
  ]
})
```


:::
::::

```{ojs}
//|label: fig-assign-validation
//|fig-cap: Model vs Observed Volume and VMT Comparison
tbEmptyCell2 = 1
```


As shown in @fig-assign-validation (Region, All Vehicles), the volume and VMT of all vehicles at the region-wide level closely matches the validation targets. Volume for all roadways is only 1.7% higher than observed and VMT for all roadways is only 1.5% higher than observed. 

As shown in @fig-assign-validation (Region, Medium Trucks) and @fig-assign-validation (Region, Heavy Trucks), the model currently overpredicts Medium and Heavy trucks. A good amount of effort was spent attempting to bring model truck volumes closer to observed. However, due to truck data limitations and other model resource considerations, further calibration was stopped. Truck modeling remains a future priority for model improvement.

In addition to the charts, the maps in @fig-assign-compare-all through @fig-assign-compare-hv shows a comparison of segment level model vs observed volumes by vehicle types. Blue represents model lower than observed and red represents model volume higher than observed.


::: {layout-ncol=3}
![Segment-Level Model vs Observed Volume Comparison -- All Vehicles](_pictures/vol-diff-Total.png){#fig-assign-compare-all}

![Segment-Level Model vs Observed Volume Comparison -- Medium Trucks](_pictures/vol-diff-MD.png){#fig-assign-compare-md}

![Segment-Level Model vs Observed Volume Comparison -- Heavy Trucks](_pictures/vol-diff-HV.png){#fig-assign-compare-hv}
:::


Looking at the *All Vehicles* map, the model volumes are lower than observed for by more than 7,500 vehicles per day for the east side of I-215 and by more than 15,000 vehicles per day for I-15 through northern Utah County. Model volumes are higher than observed volumes by more than 15,000 vehicles for I-15 in southern Salt Lake County and for I-15 in Utah County between Springville and Spanish Fork. When looking at these areas by vehicle type, volumes for both *Medium Trucks* and *Heavy Trucks* are slightly greater than observed. Overall, the volume differences between model and observed are relatively minor.

The lower arterial model vs observed volumes of *Heavy Trucks* on 9000 South in Salt Lake County was further investigated. The *Heavy Truck* observed volume for this roadway seemed much higher than expected for this roadway. The lower volumes are likely due to the observed data and not anything in the model.

## Average Travel Time

The model's average travel time was compared to observed data between (how many) various origin and destination locations throughout the model space. Observed travel times came from the Google API for various times throughout 2019. All observed data was collected on Tuesday through Thursday. Due to a data collection issue, observed average travel times were only available for the WFRC area. Model data came from the final network skims that report travel times between every TAZ by period. 

The validation results for average travel time are shown in the following figures. Looking at the EV period and knowing that evening speeds are similar to freeflow, we can deduce that in general the model’s freeflow speeds are about 10% faster than observed. In addition, a pattern exists in the AM, MD, and PM periods where shorter trips (under 20 minutes) have shorter travel times than observed and longer trips (30-60 minutes) have longer travel times than observed. This suggests that the volume-delay function (VDF) curves are slightly too aggressive on higher end facility types (freeways and arterials). Overall, while these charts show an acceptable range of error, improvements to freeflow speeds and to the VDF curves are adjustments we will consider making in future models.

```{python}
# https://drive.google.com/drive/folders/1u2CED6eGywgYnONSHTF1_xyWy4jU1cL9
# copied to data/5-assignhwy/google-api-speeds

# Use glob module to return all csv files under root directory. Create DF from this.
files = pd.DataFrame([file for file in glob.glob("data/5-assignhwy/google-api-speeds/both_time_*_2019.csv")], columns=["fullpath"])
#display(files)

files_split = files['fullpath'].str.rsplit("/", 1, expand=True).rename(columns={0: 'path', 1:'filename'})
files = files.join(files_split)

```

```{python}
df1 = pd.DataFrame()
       
for f in files['filename'].unique():
    paths = files[files['filename'] == f]['fullpath']
    dfs = [pd.read_csv(path) for path in paths] 
    concat_df = pd.concat(dfs)
    test_AM = ['both_time_6', 'both_time_7', 'both_time_8', 'both_time_9']
    for field in test_AM:
        if field in f:
            concat_df['Period']="obsAM"
    test_MD = ['both_time_11', 'both_time_12', 'both_time_13']
    for field in test_MD:
        if field in f:
            concat_df['Period']="obsMD"            
    test_PM = ['both_time_16', 'both_time_17', 'both_time_18', 'both_time_15']
    for field in test_PM:
        if field in f:
            concat_df['Period']="obsPM"            
    test_EV = ['both_time_5']
    for field in test_EV:
        if field in f:
            concat_df['Period']="obsEV"
            
    df1 = pd.concat([df1, concat_df[pd.notnull(concat_df[" DODistance"])]])
```

```{python}
df1['O_Coordinate'] = df1[' O_Coordinate'].astype(str)
df1['D_Coordinate'] = df1[' D_Coordinate'].astype(str)
df1[['O_Coordinate_X', 'O_Coordinate_Y']] = df1['O_Coordinate'].str.strip('()').str.split(',', expand=True).astype(float)
df1[['D_Coordinate_X', 'D_Coordinate_Y']] = df1['D_Coordinate'].str.strip('()').str.split(',', expand=True).astype(float)
df1 = df1.drop(columns=['O_Coordinate',' O_Coordinate', 'D_Coordinate', ' D_Coordinate', 'O_TAZID',' D_TAZID'])
```

```{python}
gdf_polygons  = gpd.read_file(geojson_file)

geometry_o = [Point(xy[::-1]) for xy in zip(df1['O_Coordinate_X'], df1['O_Coordinate_Y'])]
gdf_o = gpd.GeoDataFrame(df1, geometry=geometry_o)
o_taz_ids = gpd.sjoin(gdf_o, gdf_polygons, how='left', op='within')['TAZID']
df1['O_TAZID'] = o_taz_ids

geometry_d = [Point(xy[::-1]) for xy in zip(df1['D_Coordinate_X'], df1['D_Coordinate_Y'])]
gdf_d = gpd.GeoDataFrame(df1, geometry=geometry_d)
d_taz_ids = gpd.sjoin(gdf_d, gdf_polygons, how='left', op='within')['TAZID']
df1[' D_TAZID'] = d_taz_ids
```

```{python}
dfa=df1[['O_TAZID',' D_TAZID','Period',' ODDistance',' ODTime']].copy()
dfb=df1[['O_TAZID',' D_TAZID','Period',' DODistance',' DOTime']].copy()
dfb.rename(columns={'O_TAZID':' D_TAZID',' D_TAZID':'O_TAZID',' DODistance':' ODDistance',' DOTime':' ODTime'}, inplace=True)
dfa=pd.concat([dfa,dfb])
dfx=dfa[['O_TAZID',' D_TAZID','Period',' ODTime']]
dfx = dfx.rename(columns={' ODTime':'Time', ' D_TAZID':'D_TAZID'})
dfx['Time'] = dfx['Time'] / 60

#display(dfx)

```

```{python}
xy=dfa.groupby(['O_TAZID', ' D_TAZID','Period']).agg({' ODDistance': 'median',' ODTime':'median'})
#display(xy)

# Time Result
xx=dfx.groupby(['O_TAZID', 'D_TAZID','Period']).agg({'Time': 'median'}).unstack().Time.rename_axis([None], axis=1).reset_index()
#display(xx)

# Time Result Count
xx2=dfx.groupby(['O_TAZID', 'D_TAZID','Period']).agg({'Time': 'count'}).unstack().Time.rename_axis([None], axis=1).reset_index()
#display (xx2)
```

```{python}
def extract_values_from_omx(omx_file_path, column_name):
    """
    Extract values from the 'G_IVT' matrix in an OMX file given a set of IJ pairs.

    :param omx_file_path: Path to the OMX file
    :param column_name: Name of the column in which to store the extracted values
    :return: DataFrame with an additional column containing the extracted values
    """
    
    with omx.open_file(omx_file_path, 'r') as f:
        ivt_matrix = f['GP_IVT'][:] #/60 # Convert seconds to minutes
        #dist_matrix = f['GP_Dist'][:]
    
    #xx[column_name] = [dist_matrix[i-1, j-1] / ivt_matrix[i-1, j-1] if ivt_matrix[i-1, j-1] != 0 else 0 for i, j in zip(xx['O_TAZID'], xx[' D_TAZID'])]
    xx[column_name] = [ivt_matrix[i-1, j-1] if ivt_matrix[i-1, j-1] != 0 else 0 for i, j in zip(xx['O_TAZID'], xx['D_TAZID'])]
    
    
    return xx

# List of OMX files and corresponding column names
omx_files = ['Skm_AM.omx', 'Skm_MD.omx', 'Skm_PM.omx', 'Skm_EV.omx']
columns = ['modAM', 'modMD', 'modPM', 'modEV']

for omx_file, column_name in zip(omx_files, columns):
    xx = extract_values_from_omx(omx_path + omx_file, column_name)

#display(xx)

```

```{python}
obdTme = xx.melt(id_vars=('O_TAZID','D_TAZID'),var_name='Period',value_vars=('obsAM','obsMD','obsPM','obsEV'), value_name='tmeObs')
obdTme['Period'] = obdTme['Period'].str[3:]
#display(obdTme)

modTme = xx.melt(id_vars=('O_TAZID','D_TAZID'),var_name='Period',value_vars=('modAM','modMD','modPM','modEV'), value_name='tmeMod')
modTme['Period'] = modTme['Period'].str[3:]
#display(modTme)

dfTme = pd.DataFrame.merge(obdTme, modTme, on=('O_TAZID','D_TAZID','Period'))
#display(dfTme)
```

```{python}
ojs_define(time = dfTme) 
```

```{ojs}
html`<br/>`
viewof vPeriod = Inputs.select(new Map([['AM','AM'], ['Midday','MD'], ['PM','PM'], ['Evening', 'EV']]), {value: 'AM', label: "Period:"})

timeT = transpose(time)

timeT_filtered = timeT.filter(function(dataTme) {
    return vPeriod == dataTme.Period;
})

```

```{ojs}
calculateSlope = (data, xKey, yKey) => {
  const sumX = d3.sum(data, d => d[xKey]);
  const sumY = d3.sum(data, d => d[yKey]);
  const sumXY = d3.sum(data, d => d[xKey] * d[yKey]);
  const sumX2 = d3.sum(data, d => d[xKey] ** 2);
  
  return sumXY / sumX2;
};

slope = calculateSlope(timeT_filtered, "tmeObs", "tmeMod");

// Step 2: Define the end point for the regression line based on the slope
xMax = 60;
yMax = slope * xMax;

html`<h4>Model vs Observed Times</h4>`
Plot.plot({
  grid: true,
  width: 460,
  height: 300,
  marginRight: 40,
  x: {
    label: "Observed Time (minutes)",
    domain: [0, xMax],
    ticks: 8,
    tickFormat: d3.format(".0f")
  },
  y: {
    label: "Model Time (minutes)",
    domain: [0, xMax]
  },
  marks: [
    Plot.dot(timeT_filtered, {
      x: "tmeObs",
      y: "tmeMod",
      r: 1,
      fill: "rgb(80, 116, 230)",
      fillOpacity: 0.5,
      stroke: "none"
    }),
    Plot.line([{ x: 0, y: 0 }, { x: xMax, y: yMax }], {
      x: "x",
      y: "y",
      stroke: "rgb(80, 116, 230)",
      strokeDasharray: "4 4",
      strokeWidth: 2
    }),
    Plot.line([{ x: 0, y: 0 }, { x: xMax, y: xMax }], {
      x: "x",
      y: "y",
      stroke: "gray",
      strokeWidth: 1,
      strokeDasharray: "2 2"  // optional dashed line style for the x=y line
    })
  ]
})
```

:::