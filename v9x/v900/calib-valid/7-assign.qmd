---
title: Highway Assignment
echo: false
warning: false
message: false
---


The validation results for the Highway Assignment portion of the model are shown in this section. The observed data comes from the Utah Transit Authority 2019 On-Board Survey. 

::: {.content-visible when-format="html"}

## Table Summaries

```{python}
import pandas as pd
import numpy as np
allveh_valid = pd.read_csv("data/7-assign/wf-validation-06-30-2023-AllVeh.csv")
value_vars = ['Valid_FC', 'Valid_All']
allveh_melted = allveh_valid.melt(id_vars=['CO_FIPS', 'SEGID', 'ATYPENAME', 'Mod_AWDT', 'Obs_AWDT', 'Diff', 'Pct_Dev', 'Diff_Sq',
                                   'Mod_Car', 'Obs_Car', 'Diff_Car', 'Pct_Dev_Car', 'Diff_Sq_Car', 'Mod_MD', 'Obs_MD',
                                   'Diff_MD', 'Pct_Dev_MD', 'Diff_Sq_MD', 'Mod_HV', 'Obs_HV', 'Diff_HV', 'Pct_Dev_HV',
                                   'Diff_Sq_HV', 'DY_VMT','DY_VMT.1'], value_vars=value_vars, var_name='Valid_Type', value_name='Valid')
allveh_melted = allveh_melted[['CO_FIPS', 'SEGID', 'Valid', 'ATYPENAME', 'Mod_AWDT', 'Obs_AWDT', 'Diff', 'Pct_Dev', 'Diff_Sq',
                 'Mod_Car', 'Obs_Car', 'Diff_Car', 'Pct_Dev_Car', 'Diff_Sq_Car', 'Mod_MD', 'Obs_MD', 'Diff_MD',
                 'Pct_Dev_MD', 'Diff_Sq_MD', 'Mod_HV', 'Obs_HV', 'Diff_HV', 'Pct_Dev_HV', 'Diff_Sq_HV', 'DY_VMT','DY_VMT.1']]
allveh_melted = allveh_melted.rename(columns = {'DY_VMT':'ModelVMT', 'DY_VMT.1':'ObserveVMT'})
#allveh_melted
```

```{python}
allveh_melted2 = allveh_melted.copy()
allveh_melted2['CO_FIPS'] = 'All'
allveh = pd.concat([allveh_melted, allveh_melted2])
```

```{python}
agg_functions = {'SEGID'   : 'count',
                 'Mod_AWDT': 'mean',
                 'Obs_AWDT': 'mean',
                 'Diff_Sq' : lambda x: np.sqrt(np.sum(x) / (x.nunique() - 1)),# this is right, excel is wrong (excel is only using sum at county level)
                 'ModelVMT': 'sum',
                 'ObserveVMT': 'sum'} 

#summarize allveh_melted to create daily comparison by facility type tables
allveh_sum = allveh.groupby(['CO_FIPS','Valid']).agg(agg_functions).reset_index()
allveh_sum = allveh_sum.rename(columns={'SEGID':'NumberOfSegs', 'Mod_AWDT':'ModelVolume', 'Obs_AWDT':'CountVolume', 'Valid':'FunctionalType'})

allveh_sum['VolDiff'] = allveh_sum['ModelVolume'] - allveh_sum['CountVolume']
allveh_sum['VolPctDiff'] = (allveh_sum['ModelVolume'] / allveh_sum['CountVolume'] - 1) * 100
allveh_sum['RMSE'] = allveh_sum['Diff_Sq']
allveh_sum = allveh_sum.drop(columns={'Diff_Sq'})
allveh_sum['PctRMSE'] = (allveh_sum['RMSE'] / allveh_sum['CountVolume']) * 100
allveh_sum['VMTDiff'] = allveh_sum['ModelVMT'] - allveh_sum['ObserveVMT']
allveh_sum['VMTPctDiff'] = (allveh_sum['VMTDiff'] / allveh_sum['ObserveVMT']) * 100
allveh_sum_copy = allveh_sum.copy()

number_columns = allveh_sum.select_dtypes(include=['float64', 'int64']).columns
allveh_sum[number_columns] = allveh_sum[number_columns].round().astype(int)
allveh_sum['VolPctDiff'] = allveh_sum['VolPctDiff'].astype(str) + '%'
allveh_sum['PctRMSE'] = allveh_sum['PctRMSE'].astype(str) + '%'
allveh_sum['VMTPctDiff'] = allveh_sum['VMTPctDiff'].astype(str) + '%'
```

```{python}
allveh_vol = allveh_sum[['CO_FIPS','FunctionalType','NumberOfSegs','ModelVolume','CountVolume', 'VolDiff', 'VolPctDiff', 'RMSE', 'PctRMSE']]
allveh_vmt = allveh_sum[['CO_FIPS','FunctionalType','NumberOfSegs','ModelVMT','ObserveVMT', 'VMTDiff', 'VMTPctDiff']]
```


### Regional Summaries 
```{python}
allveh_pct = allveh_sum[['CO_FIPS','FunctionalType','VolPctDiff','VMTPctDiff']]
allveh_pct = allveh_pct.rename(columns={'VolPctDiff':'Volume', 'VMTPctDiff':'VMT'})
allveh_pct = allveh_pct.melt(id_vars = ['CO_FIPS','FunctionalType'], value_vars = ['Volume', 'VMT'], var_name = 'Variable',value_name = 'Value')
allveh_pct = allveh_pct.pivot(index=['FunctionalType','Variable'], columns='CO_FIPS', values='Value').reset_index()
allveh_pct = allveh_pct.rename(columns={3:'Box Elder', 11: 'Davis', 35: 'Salt Lake', 49: 'Utah', 57: 'Weber'})
allveh_pct = allveh_pct.sort_values(by = ['Variable','FunctionalType'], ascending =[False,False])
allveh_pct = allveh_pct[['Variable', 'FunctionalType','All', 'Box Elder', 'Weber', 'Davis', 'Salt Lake', 'Utah']]
```

```{python}
allveh_pct_exact = allveh_sum_copy[['CO_FIPS','FunctionalType','VolPctDiff','VMTPctDiff']]
allveh_pct_exact = allveh_pct_exact.rename(columns={'VolPctDiff':'Volume', 'VMTPctDiff':'VMT'})
allveh_pct_exact = allveh_pct_exact.melt(id_vars = ['CO_FIPS','FunctionalType'], value_vars = ['Volume', 'VMT'], var_name = 'Variable',value_name = 'Value')
allveh_pct_exact = allveh_pct_exact.pivot(index=['FunctionalType','Variable'], columns='CO_FIPS', values='Value').reset_index()
allveh_pct_exact = allveh_pct_exact.rename(columns={3:'Box Elder', 11: 'Davis', 35: 'Salt Lake', 49: 'Utah', 57: 'Weber'})
allveh_pct_exact = allveh_pct_exact.sort_values(by = ['Variable','FunctionalType'], ascending =[False,False])
allveh_pct_exact = allveh_pct_exact[['Variable', 'FunctionalType','All', 'Box Elder', 'Weber', 'Davis', 'Salt Lake', 'Utah']]
allveh_pct_exact = allveh_pct_exact.melt(id_vars = ['FunctionalType', 'Variable'], value_vars = ['All', 'Box Elder', 'Weber', 'Davis', 'Salt Lake', 'Utah'], value_name = 'Value', var_name = 'Region')
```

```{python}
allveh_abs_exact = allveh_sum_copy[['CO_FIPS', 'FunctionalType', 'ModelVolume', 'CountVolume', 'ModelVMT', 'ObserveVMT']]
allveh_abs_exact = allveh_abs_exact.melt(id_vars = ['CO_FIPS','FunctionalType'], value_vars = ['ModelVolume', 'CountVolume', 'ModelVMT', 'ObserveVMT'], var_name = 'DataSource',value_name = 'Value')
allveh_abs_exact['Variable'] = allveh_abs_exact['DataSource'].apply(lambda x: 'Volume' if 'Volume' in x else 'VMT')
allveh_abs_exact['DataSource'] = allveh_abs_exact['DataSource'].apply(lambda x: 'Model' if 'Model' in x else 'Observed')
allveh_abs_region = allveh_abs_exact[allveh_abs_exact['CO_FIPS'] == 'All']
```

```{python}
ojs_define(vvpct = allveh_pct)
ojs_define(vvpctLong = allveh_pct_exact)
ojs_define(vvabsLong = allveh_abs_exact)
ojs_define(vvabsLongR = allveh_abs_region)
```

```{ojs}
viewof vvSelect = Inputs.select(new Map([['Volume','Volume'], ['VMT','VMT']]), {value: 'Variable', label: "Select Summary Variable:"})
//viewof bCountySelect2 = Inputs.select(new Map([['Box Elder',3], ['Weber',57], ['Davis',11], ['Salt Lake',35], ['Utah',49], ['Region', 'All']]), {value: 'CO_FIPS', label: "Select Region:"})
```

```{ojs}
vvp = transpose(vvpct)
vvpL = transpose(vvpctLong)
vvaL = transpose(vvabsLong)
vvaLR = transpose(vvabsLongR)
table_vvData = vvp.filter(function(dataL) {
    return vvSelect == dataL.Variable;
})
stack_vvaData = vvaLR.filter(function(dataL) {
    return vvSelect == dataL.Variable; //&&
           //bCountySelect2 == dataL.CO_FIPS;
})
```

::: {.panel-tabset}
### Regional Summary Chart
```{ojs}
import {GroupedBarChart} from "@d3/grouped-bar-chart"
import {Legend, Swatches} from "@d3/color-legend"
import {howto, altplot} from "@d3/example-components"
```

```{ojs}
//|label: fig-reg-sum
//|fig-cap: Regional Summary Comparison
chart2 = GroupedBarChart(stack_vvaData, {
    x: d => d.FunctionalType,
    y: d => d.Value,
    z: d => d.DataSource,
    yLabel: "Value",
    zDomain: ['Model','Observed'],
    width,
    height: 500,
    colors: ["#376092", "#77933c"]
})
```

### Regional Summary Table
```{ojs}
//| echo: false
Inputs.table(table_vvData, {
  style: {
    fontSize: 16,
  },
  columns: [
    "FunctionalType",
    "All",
    "Box Elder",
    "Weber",
    'Davis',
    'Salt Lake',
    'Utah'
  ],
  header: {
    FunctionalType:"FT",
    All: 'Region'
  }})
```
:::

### Average Daily Comparison
```{python}
ojs_define(vol = allveh_vol)
ojs_define(vmt = allveh_vmt)
```

```{ojs}
viewof bCountySelect = Inputs.select(new Map([['Box Elder',3], ['Weber',57], ['Davis',11], ['Salt Lake',35], ['Utah',49], ['Region', 'All']]), {value: 'CO_FIPS', label: "Select Region:"})
```

```{ojs}
volT = transpose(vol)
vmtT = transpose(vmt)
filtered_volData = volT.filter(function(dataL) {
    return bCountySelect == dataL.CO_FIPS;
})
filtered_vmtData = vmtT.filter(function(dataL){
    return bCountySelect == dataL.CO_FIPS;
})
```

*Average Daily Comparison by Facility Type (Volume).*
```{ojs}
//| echo: false
Inputs.table(filtered_volData, {
  style: {
    fontSize: 16,
  },
  columns: [
    "FunctionalType",
    "NumberOfSegs",
    "ModelVolume",
    "CountVolume",
    'VolDiff',
    'VolPctDiff',
    'RMSE',
    'PctRMSE'
  ],
  header: {
    FunctionalType:"FT",
    NumberOfSegs:"NumSegs",
    ModelVolume:"Model",
    CountVolume:"Observe",
    VolDiff:'Diff',
    VolPctDiff:'PctDiff',
    RMSE:'RMSE',
    PctRMS:'PctRMSE'
  }})

```

*Average Daily Comparison by Facility Type (VMT).*
```{ojs}
//| echo: false
Inputs.table(filtered_vmtData, {
  style: {
    fontSize: 16,
  },
  columns: [
    "FunctionalType",
    "NumberOfSegs",
    "ModelVMT",
    "ObserveVMT",
    'VMTDiff',
    'VMTPctDiff'
  ],
  header: {
    FunctionalType:"FT",
    NumberOfSegs:"NumSegs",
    ModelVMT:"Model",
    ObserveVMT:"Observe",
    VMTDiff:'Diff',
    VMTPctDiff:'PctDiff'
  }})
```

:::


::: {.content-hidden when-format="html"}

![Average Daily Comparison by Facility Type by Region.](_pictures/7-plot1.png){#fig-pdf-ave-ft}

:::


## Validation Charts
Write some words here.

![Volume Comparison -- All Vehicles.](_pictures/7-plot2.png){#fig-allvehicles height="60%"}

![Volume Comparison -- Passenger Cars.](_pictures/7-plot3.png){#fig-pc height="60%"}

![Volume Comparison -- Medium Trucks.](_pictures/7-plot4.png){#fig-md-trucks height="60%"}

![Volume Comparison -- Heavy Trucks.](_pictures/7-plot5.png){#fig-hv-trucks height="60%"}


## Map Analysis
Write some words here.

![Volume Comparison -- Heavy Trucks.](_pictures/7-plot6.png){#fig-hv-trucks}

## ATO Analysis 
Access to opportunities, also referred to as accessibility or ATO, is a way to measure how well people can connect to jobs, or vice versa. ATO metrics quantify how well the current and future transportation system work with land use.  Both shorter travel times and an increased presence of employment and other opportunities result in higher accessibility scores.  

A script to calculate ATO metrics, `1_Access_to_Opportunity.s` located in the `2_ModelScripts\7_PostProcessing` folder, has been added to the modelâ€™s `_HailMary.s` batch script and runs automatically with every model run. The script sums the number of jobs and households that are within a typical commute travel shed (in minutes) by auto and transit. The typical commute travel shed is defined using a distance decay curve estimated from the 2012 household travel survey. Metrics that combine the jobs and households are also calculated.  

Results from the ATO script are output into <br>  
`7_PostProcessing\Access_to_Opportunity_@DemographicYear@.dbf`. Results can be joined with the TAZ shapefile to visualize the data, such as is shown in @fig-ato1 and @fig-ato2. 

<mark>??? Using the CompJobHHByTran and CompJobHHByAuto fields...is that right???</mark>

```{python}
import json
import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt #if using matplotlib
ato_data = pd.read_csv('data/7-assign/Access_to_Opportunity_2019.csv')
geojson_path = r'data/7-assign/tazNew.geojson'
```

```{python}
geojson_data = gpd.read_file(geojson_path)
gdf = gpd.GeoDataFrame(ato_data, geometry=geojson_data.geometry)
```

```{python}
#|label: fig-ato1
#|fig-cap: Access to opportunity by auto mode.

fig, ax = plt.subplots(1, figsize=(16,10))
gdf.plot(column='CompJobHHByAuto', cmap='YlOrRd', linewidth=.1, ax=ax, edgecolor='black', legend=False)
ax.axis('off')

# Add legend at the bottom
cbar = plt.colorbar(ax.get_children()[0], ax=ax, orientation='vertical', pad=0.05, shrink=0.3)
cbar.set_label('Composite ATO Score')

plt.show()
```

```{python}
#|label: fig-ato2
#|fig-cap: Access to opportunity by transit mode.

fig, ax = plt.subplots(1, figsize=(16,10))
gdf.plot(column='CompJobHHByTran', cmap='YlOrRd', linewidth=.1, ax=ax, edgecolor='black', legend=False)
ax.axis('off')

# Add legend at the bottom
cbar = plt.colorbar(ax.get_children()[0], ax=ax, orientation='vertical', pad=0.05, shrink=0.3)
cbar.set_label('Composite ATO Score')

plt.show()
```

